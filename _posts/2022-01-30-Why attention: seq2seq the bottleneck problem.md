---
layout: single
author_profile: false
---

A more general definition of attention:  
Given a set of vector *values*, and a vector *query*, *attention* is a technique to compute a weighted sum of the *values*, dependent on the *query*.

![alt text](https://raw.githubusercontent.com/JingchaoZhang/JingchaoZhang.github.io/master/images/cs224n-lecture8/1.png)
![alt text](https://raw.githubusercontent.com/JingchaoZhang/JingchaoZhang.github.io/master/images/cs224n-lecture8/2.png)
![alt text](https://raw.githubusercontent.com/JingchaoZhang/JingchaoZhang.github.io/master/images/cs224n-lecture8/3.png)
![alt text](https://raw.githubusercontent.com/JingchaoZhang/JingchaoZhang.github.io/master/images/cs224n-lecture8/4.png)

[Reference](http://web.stanford.edu/class/cs224n/index.html#schedule)
